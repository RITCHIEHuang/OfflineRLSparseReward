@article{levine2020offline,
  title   = {Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author  = {Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal = {arXiv preprint arXiv:2005.01643},
  year    = {2020}
}


@article{arjona-medinaRUDDERReturnDecomposition2019,
  title      = {{{RUDDER}}: Return {{Decomposition}} for {{Delayed Rewards}}},
  shorttitle = {{{RUDDER}}},
  author     = {{Arjona-Medina}, Jose A. and Gillhofer, Michael and Widrich, Michael and Unterthiner, Thomas and Brandstetter, Johannes and Hochreiter, Sepp},
  year       = {2019},
  month      = sep,
  journal    = {arXiv:1806.07857 [cs, math, stat]}
}

@article{ausinInferNetDelayedReinforcement2021,
  title      = {{{InferNet}} for {{Delayed Reinforcement Tasks}}: Addressing the {{Temporal Credit Assignment Problem}}},
  shorttitle = {{{InferNet}} for {{Delayed Reinforcement Tasks}}},
  author     = {Ausin, Markel Sanz and Azizsoltani, Hamoon and Ju, Song and Kim, Yeo Jin and Chi, Min},
  year       = {2021},
  month      = may,
  journal    = {arXiv:2105.00568 [cs]}
}

@article{azizsoltaniUnobservedNotEqual2019,
  title      = {Unobserved {{Is Not Equal}} to {{Non}}-Existent: Using {{Gaussian Processes}} to {{Infer Immediate Rewards Across Contexts}}},
  shorttitle = {Unobserved {{Is Not Equal}} to {{Non}}-Existent},
  author     = {Azizsoltani, Hamoon and Kim, Yeo Jin and Ausin, Markel Sanz and Barnes, Tiffany and Chi, Min},
  year       = {2019},
  pages      = {1974--1980}
}

@article{chapelleEmpiricalEvaluationThompson,
  title  = {An {{Empirical Evaluation}} of {{Thompson Sampling}}},
  author = {Chapelle, Olivier and Li, Lihong},
  pages  = {9},
  langid = {english}
}

@article{fuD4RLDatasetsDeep2021,
  title      = {{{D4RL}}: Datasets for {{Deep Data}}-{{Driven Reinforcement Learning}}},
  shorttitle = {{{D4RL}}},
  author     = {Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
  year       = {2021},
  month      = feb,
  journal    = {arXiv:2004.07219 [cs, stat]}
}

@article{fujimotoOffPolicyDeepReinforcement2019,
  title   = {Off-{{Policy Deep Reinforcement Learning}} without {{Exploration}}},
  author  = {Fujimoto, Scott and Meger, David and Precup, Doina},
  year    = {2019},
  month   = aug,
  journal = {arXiv:1812.02900 [cs, stat]}
}

@article{gangwaniLearningGuidanceRewards2020,
  title   = {Learning {{Guidance Rewards}} with {{Trajectory}}-Space {{Smoothing}}},
  author  = {Gangwani, Tanmay and Zhou, Yuan and Peng, Jian},
  year    = {2020},
  month   = oct,
  journal = {arXiv:2010.12718 [cs, stat]}
}

@article{goecksIntegratingBehaviorCloning2020,
  title   = {Integrating {{Behavior Cloning}} and {{Reinforcement Learning}} for {{Improved Performance}} in {{Dense}} and {{Sparse Reward Environments}}},
  author  = {Goecks, Vinicius G. and Gremillion, Gregory M. and Lawhern, Vernon J. and Valasek, John and Waytowich, Nicholas R.},
  year    = {2020},
  month   = apr,
  journal = {arXiv:1910.04281 [cs, stat]}
}

@article{hareDealingSparseRewards2019,
  title   = {Dealing with {{Sparse Rewards}} in {{Reinforcement Learning}}},
  author  = {Hare, Joshua},
  year    = {2019},
  month   = nov,
  journal = {arXiv:1910.09281 [cs, stat]}
}

@article{jannerReinforcementLearningOne2021,
  title   = {Reinforcement {{Learning}} as {{One Big Sequence Modeling Problem}}},
  author  = {Janner, Michael and Li, Qiyang and Levine, Sergey},
  year    = {2021},
  month   = jul,
  journal = {arXiv:2106.02039 [cs]}
}

@article{kostrikovOfflineReinforcementLearning2021a,
  title   = {Offline {{Reinforcement Learning}} with {{Implicit Q}}-{{Learning}}},
  author  = {Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey},
  year    = {2021},
  month   = oct,
  journal = {arXiv:2110.06169 [cs]}
}

@article{kumarConservativeQLearningOffline2020,
  title   = {Conservative {{Q}}-{{Learning}} for {{Offline Reinforcement Learning}}},
  author  = {Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  year    = {2020},
  month   = aug,
  journal = {arXiv:2006.04779 [cs, stat]}
}

@article{liuDROMODistributionallyRobust2021,
  title      = {{{DROMO}}: Distributionally {{Robust Offline Model}}-Based {{Policy Optimization}}},
  shorttitle = {{{DROMO}}},
  author     = {Liu, Ruizhen and Zhong, Dazhi and Chen, Zhicong},
  year       = {2021},
  month      = sep,
  journal    = {arXiv:2109.07275 [cs]}
}

@article{liuSequenceModelingTemporal2019,
  title   = {Sequence {{Modeling}} of {{Temporal Credit Assignment}} for {{Episodic Reinforcement Learning}}},
  author  = {Liu, Yang and Luo, Yunan and Zhong, Yuanyi and Chen, Xi and Liu, Qiang and Peng, Jian},
  year    = {2019},
  month   = may,
  journal = {arXiv:1905.13420 [cs, stat]}
}

@article{memarianSelfSupervisedOnlineReward2021a,
  title   = {Self-{{Supervised Online Reward Shaping}} in {{Sparse}}-{{Reward Environments}}},
  author  = {Memarian, Farzan and Goo, Wonjoon and Lioutikov, Rudolf and Niekum, Scott and Topcu, Ufuk},
  year    = {2021},
  month   = jul,
  journal = {arXiv:2103.04529 [cs]}
}

@article{pathakCuriositydrivenExplorationSelfsupervised2017,
  title   = {Curiosity-Driven {{Exploration}} by {{Self}}-Supervised {{Prediction}}},
  author  = {Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A. and Darrell, Trevor},
  year    = {2017},
  month   = may,
  journal = {arXiv:1705.05363 [cs, stat]}
}

@article{qinNeoRLRealWorldBenchmark2021,
  title      = {{{NeoRL}}: A {{Near Real}}-{{World Benchmark}} for {{Offline Reinforcement Learning}}},
  shorttitle = {{{NeoRL}}},
  author     = {Qin, Rongjun and Gao, Songyi and Zhang, Xingyuan and Xu, Zhen and Huang, Shengkai and Li, Zewen and Zhang, Weinan and Yu, Yang},
  year       = {2021},
  month      = feb,
  journal    = {arXiv:2102.00714 [cs]}
}

@article{sinhaS4RLSurprisinglySimple2021,
  title      = {{{S4RL}}: Surprisingly {{Simple Self}}-{{Supervision}} for {{Offline Reinforcement Learning}}},
  shorttitle = {{{S4RL}}},
  author     = {Sinha, Samarth and Mandlekar, Ajay and Garg, Animesh},
  year       = {2021},
  month      = jul,
  journal    = {arXiv:2103.06326 [cs]}
}

@article{yeMasteringAtariGames2021,
  title   = {Mastering {{Atari Games}} with {{Limited Data}}},
  author  = {Ye, Weirui and Liu, Shaohuai and Kurutach, Thanard and Abbeel, Pieter and Gao, Yang},
  year    = {2021},
  month   = oct,
  journal = {arXiv:2111.00210 [cs]}
}

@article{yuCOMBOConservativeOffline2021,
  title      = {{{COMBO}}: Conservative {{Offline Model}}-{{Based Policy Optimization}}},
  shorttitle = {{{COMBO}}},
  author     = {Yu, Tianhe and Kumar, Aviral and Rafailov, Rafael and Rajeswaran, Aravind and Levine, Sergey and Finn, Chelsea},
  year       = {2021},
  month      = feb,
  journal    = {arXiv:2102.08363 [cs]}
}

@article{yuMOPOModelbasedOffline2020,
  title      = {{{MOPO}}: Model-Based {{Offline Policy Optimization}}},
  shorttitle = {{{MOPO}}},
  author     = {Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  year       = {2020},
  month      = sep,
  journal    = {arXiv:2005.13239 [cs, stat]}
}

@inproceedings{zhangCounterfactualRewardModification2021,
  title     = {Counterfactual {{Reward Modification}} for {{Streaming Recommendation}} with {{Delayed Feedback}}},
  booktitle = {Proceedings of the 44th {{International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author    = {Zhang, Xiao and Jia, Haonan and Su, Hanjing and Wang, Wenhan and Xu, Jun and Wen, Ji-Rong},
  year      = {2021},
  month     = jul,
  pages     = {41--50},
  publisher = {{ACM}},
  address   = {{Virtual Event Canada}},
  doi       = {10.1145/3404835.3462892},
  isbn      = {978-1-4503-8037-9},
  langid    = {english}
}


@article{ieRecSimConfigurableSimulation2019,
  title      = {{{RecSim}}: A {{Configurable Simulation Platform}} for {{Recommender Systems}}},
  shorttitle = {{{RecSim}}},
  author     = {Ie, Eugene and Hsu, Chih-wei and Mladenov, Martin and Jain, Vihan and Narvekar, Sanmit and Wang, Jing and Wu, Rui and Boutilier, Craig},
  year       = {2019},
  month      = sep,
  journal    = {arXiv:1909.04847 [cs, stat]}
}

@article{brockmanOpenAIGym2016,
  title   = {{{OpenAI Gym}}},
  author  = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  year    = {2016},
  month   = jun,
  journal = {arXiv:1606.01540 [cs]}
}

@misc{haarnoja2018soft,
  title         = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author        = {Tuomas Haarnoja and Aurick Zhou and Pieter Abbeel and Sergey Levine},
  year          = {2018},
  eprint        = {1801.01290},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@inproceedings{ngPolicyInvarianceReward1999,
  title      = {Policy Invariance under Reward Transformations: Theory and Application to Reward Shaping},
  shorttitle = {Policy Invariance under Reward Transformations},
  booktitle  = {In {{Proceedings}} of the {{Sixteenth International Conference}} on {{Machine Learning}}},
  author     = {Ng, Andrew Y. and Harada, Daishi and Russell, Stuart},
  year       = {1999},
  pages      = {278--287},
  publisher  = {{Morgan Kaufmann}}
}


@article{Peters:2010,
  author  = {Peters, J. },
  title   = {{P}olicy gradient methods},
  year    = {2010},
  journal = {Scholarpedia},
  volume  = {5},
  number  = {11},
  pages   = {3698},
  doi     = {10.4249/scholarpedia.3698},
  note    = {revision \#137199}
}